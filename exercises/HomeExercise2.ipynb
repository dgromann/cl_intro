{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZdWuW5ntOCTZOEe5tjkal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/cl_intro/blob/main/exercises/HomeExercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home Exercise 2a: Obtaining statistics on a text with NLP\n",
        "\n",
        "\n",
        "\n",
        "In this first home exercise, you will use the knowledge from Tutorial 1 and TUtorial 2 in order to perform some preprocessing steps and calculate some basic statistics on a news article of your choice. You can find an example new article in the following code cell. Feel free to replace the URL with a news article of your choice, however, keep in mind for now it should be limited to the English language."
      ],
      "metadata": {
        "id": "itxuVJHj2G2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya9BXq2h2GGs"
      },
      "outputs": [],
      "source": [
        "!pip3 install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import newspaper\n",
        "from newspaper import Article\n",
        "\n",
        "url = 'https://edition.cnn.com/2023/11/15/politics/biden-xi-meeting'\n",
        "\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "\n",
        "#This line displays the authors of the article\n",
        "print(\"Authors: \", article.authors, \"\\n\")\n",
        "\n",
        "#This line displays the title and entire text of the article\n",
        "print(\"Title: \", article.title, \"\\n\")\n",
        "print(\"Text of article: \\n\", article.text)"
      ],
      "metadata": {
        "id": "CTN4bKv93zh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ Use the above article or a news article of your choice and print the number of unique words in the text.\n"
      ],
      "metadata": {
        "id": "2hbxkjsx4TwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the number of unique words in the text"
      ],
      "metadata": {
        "id": "ODInpdk24TAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "\n",
        "ðŸ‘‹ âš’ Now perform the following preprocessing steps and see how the number of unique words changes:\n",
        "\n",
        "\n",
        "1.   Lower case all words in the text\n",
        "2.   Remove punctuation markers and numbers (Hint: string.isalpha())\n",
        "3.   Lemmatize all words in the text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1CmFPP7N4oMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and then calculate the number of unique words in the text again"
      ],
      "metadata": {
        "id": "YbKQIzoh4moQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ How many of these unique lemmas after preprocessing are in WordNet? Calculate the number by querying WordNet and check if the lemma is in WordNet or not."
      ],
      "metadata": {
        "id": "5FMEIyzO5di4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "NjBKg_535nx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER\n",
        "\n",
        "You will compare the difference of the NER performance of three different models in spaCy. A description of the type of available models is in the [spaCy documentation](https://spacy.io/models/en). This is how the three different model sizes are installed.\n",
        "\n"
      ],
      "metadata": {
        "id": "S9ultBis5MJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "AAKOT-Lf5-IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’  Use each of the three models that were downloaded above and perform named entitiy recognition with each of them.\n",
        "\n",
        "1.   Do you notice any difference between the performance of the different models?\n",
        "2.   How many NERs of each type are there in each model?\n",
        "\n"
      ],
      "metadata": {
        "id": "5UIl_Ihc5-gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp_sm = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "PYvQD4Cb60Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the following function to visualize the named entities in the text in order to facilitate the analysis."
      ],
      "metadata": {
        "id": "aPFAJY7q61XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also visualize the dependency relations\n",
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "dj7tYVJa61kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ Add your text of the analysis of differences between the three different models right here in the next text field."
      ],
      "metadata": {
        "id": "7UTrkzPC77cK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your analysis  "
      ],
      "metadata": {
        "id": "3LEMh9u-8IEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home Exercise 2b: Evaluate analogy performance per relation type\n",
        "\n",
        "ðŸ‘‹ âš’ Run through the Tutorial3.txt file from Tutorial3 and use your analogy function to evaluate how well the embeddings perform, however, this time calculate the accuracy for each relation type, e.g. `capital-common-countries`, separately. THe relationtypes are marked with `: `at the beginning of the line.  \n"
      ],
      "metadata": {
        "id": "-TGQOmG1xJtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here"
      ],
      "metadata": {
        "id": "Y7FhqiKqxQwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}